{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Classification using Convolutional Neural Networks\n",
    "## Tensorflow-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suppress useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the fashion-mnist train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a 20% validation split from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation set with 20 percent examples from training set\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Add the color channel axis for Keras operations.\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_validate = x_validate[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Label Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    0: 'T-shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6, 6, figsize = (12, 12))\n",
    "fig.suptitle('First few images in Fashion MNIST Dataset')\n",
    "fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
    "for x, y in [(i, j) for i in range(6) for j in range(6)]:\n",
    "    ax[x, y].imshow(x_train[x + y * 6].reshape((28, 28)), cmap = 'gray')\n",
    "    title = label_dict[int(y_train[x + y * 6])]\n",
    "    ax[x, y].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimension:\n",
    "# WxHxC where W is the Width, H is the Height and C is the number of color channels\n",
    "img_dim = (x_train[0].shape[0], x_train[0].shape[1], 1)\n",
    "print(\"Input image dimension: \", img_dim)\n",
    "\n",
    "# Define hyper-parameters\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Input Convolution layer, f-64, k-2, p-same, a-relu\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=img_dim))\n",
    "\n",
    "# Max Pooling Layer, p2\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Dropout of 0.3\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "# Convolution layer, f-32, k-2, p-same, a-relu\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "\n",
    "# # Max Pooling Layer, p2\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Dropout of 0.3\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "# Flatten the activations of previous layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Fully connected dense layer, fc-256, a-relu\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Dropout of 0.5\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Fully connected dense layer, fc-num_classes, a-softmax\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Convolution Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/convolution_basic.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Operation on RGB images using 3D kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/convolution.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to save the training history\n",
    "history_dict = {}\n",
    "\n",
    "# Compile the CNN model\n",
    "# We are using here sparse_categorical_crossentropy loss function and Adam optimizer.\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs, verbose=1,\n",
    "    validation_data=(x_validate, y_validate)\n",
    "    )\n",
    "\n",
    "history_dict['first_model'] = history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Validation accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "for history in history_dict:\n",
    "    val_acc = history_dict[history].history['val_acc']\n",
    "    val_loss = history_dict[history].history['val_loss']\n",
    "    ax1.plot(val_acc, label=history)\n",
    "    ax2.plot(val_loss, label=history)\n",
    "    \n",
    "ax1.set_ylabel('validation accuracy')\n",
    "ax2.set_ylabel('validation loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and compare validation and training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history_dict[history].history['acc']\n",
    "val_accuracy = history_dict[history].history['val_acc']\n",
    "loss = history_dict[history].history['loss']\n",
    "val_loss = history_dict[history].history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on a test set (not seen by the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(x_test)\n",
    "\n",
    "#get the indices to be plotted\n",
    "#y_true = test_df.iloc[:, 0]\n",
    "y_true = y_test\n",
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find embeddings for PCA and tSNE dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(pd.read_csv('data/fashion-mnist_test.csv'), dtype='float32')\n",
    "\n",
    "embed_count = 900\n",
    "x_test = test_data[:embed_count, 1:] / 255\n",
    "y_test = test_data[:embed_count, 0]\n",
    "\n",
    "logdir = os.getcwd()+'/fmnist_embedding_logdir/' #change this\n",
    "\n",
    "# setup the write and embedding tensor\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(logdir)\n",
    "\n",
    "embedding_var = tf.Variable(x_test, name='fmnist_embedding')\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "embedding.metadata_path = logdir + 'metadata.tsv'\n",
    "embedding.sprite.image_path = logdir + 'sprite.png'\n",
    "embedding.sprite.single_image_dim.extend([28, 28])\n",
    "\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "# run the sesion to create the model check point\n",
    "\n",
    "with tf.Session() as sesh:\n",
    "    sesh.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sesh, logdir + 'model.ckpt')\n",
    "    \n",
    "    \n",
    "# create the sprite image and the metadata file\n",
    "\n",
    "rows = 28\n",
    "cols = 28\n",
    "\n",
    "label = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "          'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boot']\n",
    "\n",
    "sprite_dim = int(np.sqrt(x_test.shape[0]))\n",
    "\n",
    "sprite_image = np.ones((cols * sprite_dim, rows * sprite_dim))\n",
    "\n",
    "index = 0\n",
    "labels = []\n",
    "for i in range(sprite_dim):\n",
    "    for j in range(sprite_dim):\n",
    "        \n",
    "        labels.append(label[int(y_test[index])])\n",
    "        \n",
    "        sprite_image[\n",
    "            i * cols: (i + 1) * cols,\n",
    "            j * rows: (j + 1) * rows\n",
    "        ] = x_test[index].reshape(28, 28) * -1 + 1\n",
    "        \n",
    "        index += 1\n",
    "        \n",
    "with open(embedding.metadata_path, 'w') as meta:\n",
    "    meta.write('Index\\tLabel\\n')\n",
    "    for index, label in enumerate(labels):\n",
    "        meta.write('{}\\t{}\\n'.format(index, label))\n",
    "        \n",
    "plt.imsave(embedding.sprite.image_path, sprite_image, cmap='gray')\n",
    "plt.imshow(sprite_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For TensorBoard PCA and tSNE visualization, run this in a new terminal:\n",
    "\n",
    "**tensorboard --port 8889 --logdir ./fmnist_embedding_logdir/**\n",
    "\n",
    "After you run this in a terminal, in a new tab go to **yourIP:8889**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Sequential model\n",
    "model2 = \n",
    "\n",
    "# Input Convolution layer, f-128, k-2, p-same, a-relu\n",
    "\n",
    "# Max Pooling Layer, p2\n",
    "\n",
    "# Dropout of 0.25\n",
    "\n",
    "# Input Convolution layer, f-64, k-2, p-same, a-relu\n",
    "\n",
    "# Max Pooling Layer, p2\n",
    "\n",
    "# Dropout of 0.25\n",
    "\n",
    "# Convolution layer, f-32, k-2, p-same, a-relu\n",
    "\n",
    "# # Max Pooling Layer, p2\n",
    "\n",
    "# Dropout of 0.3\n",
    "\n",
    "# Flatten the activations of previous layer\n",
    "\n",
    "# Fully connected dense layer, fc-256, a-relu\n",
    "\n",
    "# Dropout of 0.5\n",
    "\n",
    "# Fully connected dense layer, fc-num_classes, a-softmax\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to save the training history\n",
    "history_dict = {}\n",
    "\n",
    "# Compile the CNN model\n",
    "# We are using here sparse_categorical_crossentropy loss function and Adam optimizer.\n",
    "model2.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "history = model2.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs, verbose=1,\n",
    "    validation_data=(x_validate, y_validate)\n",
    "    )\n",
    "\n",
    "history_dict['second_model'] = history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Validation accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "for history in history_dict:\n",
    "    val_acc = history_dict[history].history['val_acc']\n",
    "    val_loss = history_dict[history].history['val_loss']\n",
    "    ax1.plot(val_acc, label=history)\n",
    "    ax2.plot(val_loss, label=history)\n",
    "    \n",
    "ax1.set_ylabel('validation accuracy')\n",
    "ax2.set_ylabel('validation loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and compare validation and training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history_dict[history].history['acc']\n",
    "val_accuracy = history_dict[history].history['val_acc']\n",
    "loss = history_dict[history].history['loss']\n",
    "val_loss = history_dict[history].history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on a test set (not seen by the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#get the predictions for the test data\n",
    "predicted_classes = model2.predict_classes(x_test)\n",
    "\n",
    "#get the indices to be plotted\n",
    "y_true = test_df.iloc[:, 0]\n",
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
