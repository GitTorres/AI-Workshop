{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple text classifier with tf.estimator and tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /home/student/.local/lib/python3.5/site-packages (0.1.1)\r\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/student/.local/lib/python3.5/site-packages (from tensorflow_hub) (1.15.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /home/student/.local/lib/python3.5/site-packages (from tensorflow_hub) (1.11.0)\r\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /home/student/.local/lib/python3.5/site-packages (from tensorflow_hub) (3.6.0)\r\n",
      "Requirement already satisfied: setuptools in /home/student/.local/lib/python3.5/site-packages (from protobuf>=3.4.0->tensorflow_hub) (40.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install tensorflow_hub library\n",
    "!pip install tensorflow_hub --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suppress useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: This dataset contains movie reviews along with their associated binary sentiment polarity labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in training:  6920\n",
      "Number of Samples in testing:  1821\n",
      "Training data looks like:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A stirring, funny and finally transporting re-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Apparently reassembled from the cutting-room f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They presume their audience won't sit still fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a visually stunning rumination on love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Jonathan Parker's Bartleby should have been th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      1  A stirring, funny and finally transporting re-...\n",
       "1      0  Apparently reassembled from the cutting-room f...\n",
       "2      0  They presume their audience won't sit still fo...\n",
       "3      1  This is a visually stunning rumination on love...\n",
       "4      1  Jonathan Parker's Bartleby should have been th..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/text/train_binary_sent.csv') \n",
    "test_df = pd.read_csv('data/text/test_binary_sent.csv')\n",
    "\n",
    "print('Number of Samples in training: ', len(train_df))\n",
    "print('Number of Samples in testing: ', len(test_df))\n",
    "print('Training data looks like:\\n')\n",
    "\n",
    "# Sample\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look into few samples [0 = Negative, 1 = Positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      " Jonathan Parker's Bartleby should have been the be-all-end-all of the modern-office anomie films.\n",
      "\n",
      "\n",
      "Polarity: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Review:\\n\\n\",train_df.iloc[4].sentence)\n",
    "print(\"\\n\\nPolarity:\",train_df.iloc[4].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Model Using tensorflow's Estimator framework:\n",
    "\n",
    "### 1. Estimator framework provides input functions that wrap Pandas dataframes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(x=train_df, \n",
    "                                                     y=train_df[\"label\"], \n",
    "                                                     num_epochs=None,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(x=train_df,\n",
    "                                                             y=train_df[\"label\"],\n",
    "                                                             shuffle=False)\n",
    "\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(x=test_df, \n",
    "                                                            y=test_df[\"label\"], \n",
    "                                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Feature Columns:\n",
    "\n",
    "TF-Hub provides a feature column that applies a module on the given text feature and passes further the outputs of the module. In this tutorial we will be using the nnlm-en-dim128 module. For the purpose of this tutorial, the most important facts are:\n",
    "\n",
    "1. The module takes a batch of sentences in a 1-D tensor of strings as input.\n",
    "2. The module is responsible for preprocessing of sentences (e.g. removal of punctuation and splitting on spaces).\n",
    "3. The module works with any input (e.g. nnlm-en-dim128 hashes words not present in vocabulary into ~20.000 buckets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n",
      "INFO:tensorflow:Module 'https://tfhub.dev/google/nnlm-en-dim128/1' already being downloaded by 'utsa-ai-75.4267.c0f4a933e2e04f05be0cc7007ce65b19'. Waiting.\n"
     ]
    }
   ],
   "source": [
    "embedded_text_feature_column = hub.text_embedding_column(key=\"sentence\", # embed the text\n",
    "                                                         module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\",# embedding type\n",
    "                                                         trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Estimator\n",
    "\n",
    "For classification we can use a DNN Classifier, and specify the hidden layers and other properties of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.DNNClassifier(hidden_units=[512, 128],\n",
    "                                       feature_columns=[embedded_text_feature_column],\n",
    "                                       n_classes=2,\n",
    "                                       activation_fn = tf.nn.relu,\n",
    "                                       optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for 1,000 steps means 128,000 training examples with the default\n",
    "# batch size. This is roughly equivalent to 5 epochs since the training dataset\n",
    "# contains 25,000 examples.\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, # training using train input function declared above\n",
    "                steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "## EVAL\n",
    "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "print (\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
    "print (\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
